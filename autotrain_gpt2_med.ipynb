{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":99711,"status":"ok","timestamp":1703270241235,"user":{"displayName":"Ramy","userId":"07137063187677220139"},"user_tz":-60},"id":"JvMRbVLEJlZT","outputId":"89832171-e682-4b4c-e378-e9b52ec1eb43"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m> \u001b[1mINFO    Installing latest xformers\u001b[0m\n","> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"]}],"source":["#@title ðŸ¤— AutoTrain LLM\n","#@markdown In order to use this colab\n","#@markdown - upload train.csv to a folder named `data/`\n","#@markdown - train.csv must contain a `text` column\n","#@markdown - choose a project name if you wish\n","#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n","#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n","#@markdown - update hyperparameters if you wish\n","#@markdown - click `Runtime > Run all` or run each cell individually\n","\n","import os\n","!pip install -U autotrain-advanced > install_logs.txt\n","!autotrain setup > setup_logs.txt"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["46b3d44894e14e5ab486d1b9d6aefe01","0aaad9c9c9a54bd1ac96bd56642ab50e","78ac3a5f84e349ec98a82fc24c5fd7a3","274be5774d064ae58234b2dd97395ce3","fd14948de6a840fa86dff66153a4afbc","2aa1e0640bb54cd3812a5b0f9e019f77","f1a3135e5daf48f49f872b7d9737a18a","91e6ea75794b4e458806ddca4ebf569b","1828ff91e5484015aaff4f2fe3567f0a","b727086f1ed546a5bb5f756b546d25f8","70fff442a717469687add4cdd988d418"]},"executionInfo":{"elapsed":4495,"status":"ok","timestamp":1703272174799,"user":{"displayName":"Ramy","userId":"07137063187677220139"},"user_tz":-60},"id":"DaLvfFJJuUSD","outputId":"4953d59f-7ed3-4b0e-c6d0-31677b9302c6"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46b3d44894e14e5ab486d1b9d6aefe01","version_major":2,"version_minor":0},"text/plain":["Creating CSV from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["3219350"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","\n","# Load the \"squad\" dataset, \"train\" split\n","dataset = load_dataset(\"medalpaca/medical_meadow_wikidoc_patient_information\", split=\"train\")\n","\n","# Save the dataset as a CSV file\n","dataset.to_csv(\"train.csv\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1060,"status":"ok","timestamp":1703272186904,"user":{"displayName":"Ramy","userId":"07137063187677220139"},"user_tz":-60},"id":"39bvPuDCvC9c"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"train.csv\")\n","selected_column = df[\"output\"]\n","new_df = pd.DataFrame({\"text\": selected_column})  # Rename the column to \"text\"\n","new_df.to_csv(\"/content/data/train.csv\", index=False)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"cellView":"form","executionInfo":{"elapsed":4,"status":"ok","timestamp":1703275281593,"user":{"displayName":"Ramy","userId":"07137063187677220139"},"user_tz":-60},"id":"A2-_lkBS1WKA"},"outputs":[],"source":["#@markdown ---\n","#@markdown #### Project Config\n","#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n","project_name = 'medgpt2' # @param {type:\"string\"}\n","model_name = '' # @param {type:\"string\"}\n","\n","#@markdown ---\n","#@markdown #### Push to Hub?\n","#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n","#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n","#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n","#@markdown You can find your token here: https://huggingface.co/settings/tokens\n","push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","hf_token = \"\" #@param {type:\"string\"}\n","repo_id = \"\" #@param {type:\"string\"}\n","\n","#@markdown ---\n","#@markdown #### Hyperparameters\n","learning_rate = 2e-4 # @param {type:\"number\"}\n","num_epochs = 2 #@param {type:\"number\"}\n","batch_size = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n","block_size = 100 # @param {type:\"number\"}\n","trainer = \"sft\" # @param [\"default\", \"sft\"] {type:\"raw\"}\n","warmup_ratio = 0.1 # @param {type:\"number\"}\n","weight_decay = 0.01 # @param {type:\"number\"}\n","gradient_accumulation = 4 # @param {type:\"number\"}\n","use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","use_peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","use_int4 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","lora_r = 16 #@param {type:\"number\"}\n","lora_alpha = 32 #@param {type:\"number\"}\n","lora_dropout = 0.05 #@param {type:\"number\"}\n","\n","os.environ[\"PROJECT_NAME\"] = project_name\n","os.environ[\"MODEL_NAME\"] = model_name\n","os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n","os.environ[\"HF_TOKEN\"] = hf_token\n","os.environ[\"REPO_ID\"] = repo_id\n","os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n","os.environ[\"NUM_EPOCHS\"] = str(num_epochs)\n","os.environ[\"BATCH_SIZE\"] = str(batch_size)\n","os.environ[\"BLOCK_SIZE\"] = str(block_size)\n","os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n","os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n","os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n","os.environ[\"USE_FP16\"] = str(use_fp16)\n","os.environ[\"USE_PEFT\"] = str(use_peft)\n","os.environ[\"USE_INT4\"] = str(use_int4)\n","os.environ[\"LORA_R\"] = str(lora_r)\n","os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n","os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"g3cd_ED_yXXt","outputId":"bfff2aa8-8d4c-49ab-d5cd-75fe97c35d6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["> \u001b[1mINFO    Running LLM\u001b[0m\n","> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.01, max_grad_norm=1.0, add_eos_token=False, block_size=100, peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization=None, model_max_length=1024, trainer='default', target_modules=None, merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, train=True, deploy=False, inference=False, username=None, backend='local-cli', token='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', repo_id='ramy21/med5', push_to_hub=True, model='tiiuae/falcon-7b', project_name='medgpt2', seed=42, epochs=2, gradient_accumulation=4, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='data/', train_split='train', valid_split=None, batch_size=4, func=<function run_llm_command_factory at 0x7c5115fc6950>)\u001b[0m\n","> \u001b[1mINFO    Dataset: medgpt2 (lm_training)\n","Train data: ['data//train.csv']\n","Valid data: []\n","Column mapping: {'text': 'text', 'rejected_text': 'rejected', 'prompt': 'prompt'}\n","\u001b[0m\n","\rSaving the dataset (0/1 shards):   0% 0/5942 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 5942/5942 [00:00<00:00, 978237.41 examples/s]\rSaving the dataset (1/1 shards): 100% 5942/5942 [00:00<00:00, 953717.83 examples/s]\n","\rSaving the dataset (0/1 shards):   0% 0/5942 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 5942/5942 [00:00<00:00, 1150041.73 examples/s]\rSaving the dataset (1/1 shards): 100% 5942/5942 [00:00<00:00, 1120920.86 examples/s]\n","> \u001b[1mINFO    Starting local training...\u001b[0m\n","> \u001b[1mINFO    {\"model\":\"tiiuae/falcon-7b\",\"project_name\":\"medgpt2\",\"data_path\":\"medgpt2/autotrain-data\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":100,\"model_max_length\":1024,\"trainer\":\"default\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":2,\"batch_size\":4,\"warmup_ratio\":0.1,\"gradient_accumulation\":4,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.01,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":null,\"target_modules\":null,\"merge_adapter\":false,\"peft\":false,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"autotrain_prompt\",\"text_column\":\"autotrain_text\",\"rejected_text_column\":\"autotrain_rejected_text\",\"push_to_hub\":true,\"repo_id\":\"ramy21/med5\",\"username\":null,\"token\":\"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\"}\u001b[0m\n","> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'medgpt2/training_params.json']\u001b[0m\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n","  warnings.warn(\n","\u001b[1mðŸš€ INFO  \u001b[0m | \u001b[32m2023-12-22 20:01:42\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n","\u001b[1mðŸš€ INFO  \u001b[0m | \u001b[32m2023-12-22 20:01:42\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n","    features: ['autotrain_text'],\n","    num_rows: 5942\n","})\u001b[0m\n","\u001b[1mðŸš€ INFO  \u001b[0m | \u001b[32m2023-12-22 20:01:42\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n","tokenizer_config.json: 100% 287/287 [00:00<00:00, 1.42MB/s]\n","tokenizer.json: 100% 2.73M/2.73M [00:00<00:00, 10.1MB/s]\n","special_tokens_map.json: 100% 281/281 [00:00<00:00, 1.49MB/s]\n","config.json: 100% 1.05k/1.05k [00:00<00:00, 5.72MB/s]\n","configuration_falcon.py: 100% 7.16k/7.16k [00:00<00:00, 30.9MB/s]\n","A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- configuration_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","\n","WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n","\n","modeling_falcon.py: 100% 56.9k/56.9k [00:00<00:00, 140MB/s]\n","A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- modeling_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","pytorch_model.bin.index.json: 100% 16.9k/16.9k [00:00<00:00, 60.3MB/s]\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","pytorch_model-00001-of-00002.bin:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 31.5M/9.95G [00:00<00:32, 304MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 73.4M/9.95G [00:00<00:27, 362MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 115M/9.95G [00:00<00:30, 327MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 157M/9.95G [00:00<00:40, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 189M/9.95G [00:00<00:42, 230MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 220M/9.95G [00:00<00:42, 228MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 252M/9.95G [00:01<00:43, 224MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 283M/9.95G [00:01<00:42, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 315M/9.95G [00:01<00:43, 221MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 346M/9.95G [00:01<00:43, 223MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 377M/9.95G [00:01<00:43, 221MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 409M/9.95G [00:01<00:40, 235MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 440M/9.95G [00:01<00:39, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 472M/9.95G [00:02<00:43, 220MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 503M/9.95G [00:02<00:44, 213MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 535M/9.95G [00:02<00:42, 219MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 566M/9.95G [00:02<01:16, 122MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 587M/9.95G [00:02<01:10, 132MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 608M/9.95G [00:03<01:05, 142MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 640M/9.95G [00:03<00:56, 166MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 661M/9.95G [00:03<00:53, 172MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 682M/9.95G [00:03<00:52, 176MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 703M/9.95G [00:03<00:54, 170MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 724M/9.95G [00:03<01:04, 143MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 744M/9.95G [00:03<01:09, 133MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 765M/9.95G [00:05<03:50, 39.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 797M/9.95G [00:05<02:39, 57.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 818M/9.95G [00:05<02:17, 66.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 839M/9.95G [00:05<01:52, 80.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 870M/9.95G [00:05<01:22, 110MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 902M/9.95G [00:06<01:07, 134MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 923M/9.95G [00:06<01:03, 143MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 944M/9.95G [00:06<00:59, 152MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 975M/9.95G [00:06<00:50, 178MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.01G/9.95G [00:06<00:43, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.04G/9.95G [00:06<00:43, 203MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.07G/9.95G [00:06<00:42, 210MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.10G/9.95G [00:06<00:38, 229MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.13G/9.95G [00:07<00:36, 240MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.16G/9.95G [00:07<00:34, 258MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.20G/9.95G [00:10<04:59, 29.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.22G/9.95G [00:10<04:01, 36.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.24G/9.95G [00:10<03:27, 41.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.26G/9.95G [00:11<03:06, 46.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.28G/9.95G [00:11<02:41, 53.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.30G/9.95G [00:11<02:28, 58.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.32G/9.95G [00:11<02:29, 57.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.35G/9.95G [00:12<01:45, 81.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.38G/9.95G [00:12<01:18, 109MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.42G/9.95G [00:12<01:02, 136MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.45G/9.95G [00:12<00:53, 160MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.48G/9.95G [00:12<00:44, 188MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.51G/9.95G [00:12<00:40, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.54G/9.95G [00:12<00:37, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.57G/9.95G [00:12<00:39, 212MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.60G/9.95G [00:13<00:36, 229MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.64G/9.95G [00:13<00:35, 234MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.67G/9.95G [00:13<00:33, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.70G/9.95G [00:13<00:33, 246MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.73G/9.95G [00:13<00:31, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.76G/9.95G [00:13<00:32, 253MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.79G/9.95G [00:13<00:34, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.82G/9.95G [00:13<00:38, 212MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.86G/9.95G [00:14<00:36, 220MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.89G/9.95G [00:14<00:38, 210MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.92G/9.95G [00:14<00:35, 224MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.95G/9.95G [00:14<00:40, 197MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.97G/9.95G [00:14<00:40, 199MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.00G/9.95G [00:14<00:38, 209MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.03G/9.95G [00:15<01:10, 112MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.06G/9.95G [00:15<01:04, 122MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.08G/9.95G [00:15<00:59, 132MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.10G/9.95G [00:15<00:53, 146MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.13G/9.95G [00:15<00:43, 178MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.16G/9.95G [00:15<00:38, 203MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.19G/9.95G [00:16<00:34, 223MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.22G/9.95G [00:16<00:38, 199MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.25G/9.95G [00:16<00:43, 176MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.28G/9.95G [00:16<00:45, 168MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.30G/9.95G [00:16<00:44, 173MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.33G/9.95G [00:16<00:40, 189MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.36G/9.95G [00:16<00:36, 209MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.39G/9.95G [00:17<00:35, 214MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.42G/9.95G [00:17<00:34, 220MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.45G/9.95G [00:17<00:33, 224MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.49G/9.95G [00:18<01:44, 71.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.51G/9.95G [00:20<03:51, 32.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.54G/9.95G [00:20<02:48, 43.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.56G/9.95G [00:20<02:22, 51.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.58G/9.95G [00:20<01:55, 63.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.61G/9.95G [00:20<01:23, 87.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.64G/9.95G [00:21<01:08, 106MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.66G/9.95G [00:21<01:01, 118MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.69G/9.95G [00:21<00:49, 148MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.73G/9.95G [00:21<00:42, 171MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.76G/9.95G [00:21<00:36, 196MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.79G/9.95G [00:21<00:34, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.82G/9.95G [00:21<00:32, 221MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.85G/9.95G [00:22<00:54, 130MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.87G/9.95G [00:22<01:05, 107MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.89G/9.95G [00:22<01:10, 99.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.92G/9.95G [00:23<01:09, 101MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.94G/9.95G [00:23<01:16, 92.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.96G/9.95G [00:23<01:18, 89.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.97G/9.95G [00:23<01:19, 87.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.98G/9.95G [00:23<01:25, 81.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.99G/9.95G [00:24<01:22, 84.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.02G/9.95G [00:25<02:47, 41.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.03G/9.95G [00:25<02:36, 44.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.06G/9.95G [00:25<01:43, 66.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.08G/9.95G [00:25<01:28, 77.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.10G/9.95G [00:25<01:12, 94.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.14G/9.95G [00:25<00:55, 124MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.17G/9.95G [00:26<00:46, 147MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.19G/9.95G [00:26<00:43, 154MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.21G/9.95G [00:26<00:40, 165MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.24G/9.95G [00:26<00:35, 187MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.27G/9.95G [00:26<00:31, 210MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.30G/9.95G [00:26<00:28, 235MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.33G/9.95G [00:26<00:27, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.37G/9.95G [00:26<00:26, 248MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.40G/9.95G [00:27<00:25, 258MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.43G/9.95G [00:27<00:26, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.46G/9.95G [00:27<00:25, 256MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.49G/9.95G [00:27<00:27, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.52G/9.95G [00:27<00:28, 224MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.55G/9.95G [00:27<00:29, 214MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.59G/9.95G [00:27<00:30, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.62G/9.95G [00:28<00:29, 218MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.65G/9.95G [00:28<00:29, 214MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.68G/9.95G [00:28<00:27, 228MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.71G/9.95G [00:28<00:28, 216MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.74G/9.95G [00:28<00:30, 205MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.76G/9.95G [00:28<00:30, 200MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.79G/9.95G [00:28<00:31, 199MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.81G/9.95G [00:30<02:12, 46.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.83G/9.95G [00:30<01:47, 56.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.85G/9.95G [00:30<01:26, 70.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.87G/9.95G [00:30<01:16, 79.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.90G/9.95G [00:30<00:56, 106MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.93G/9.95G [00:30<00:44, 136MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.96G/9.95G [00:31<00:38, 156MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.00G/9.95G [00:31<00:41, 142MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.02G/9.95G [00:31<00:47, 125MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.04G/9.95G [00:31<00:43, 137MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.07G/9.95G [00:31<00:35, 166MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.10G/9.95G [00:31<00:29, 196MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.13G/9.95G [00:32<00:28, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.16G/9.95G [00:32<00:25, 226MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.19G/9.95G [00:32<00:35, 162MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.24G/9.95G [00:32<00:28, 204MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.28G/9.95G [00:32<00:23, 242MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.32G/9.95G [00:32<00:22, 246MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.35G/9.95G [00:33<00:23, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.38G/9.95G [00:33<00:21, 254MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.41G/9.95G [00:35<02:06, 43.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.44G/9.95G [00:35<01:54, 48.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.46G/9.95G [00:35<01:43, 52.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.48G/9.95G [00:36<01:25, 64.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.51G/9.95G [00:36<01:05, 83.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.54G/9.95G [00:36<00:50, 108MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.57G/9.95G [00:36<00:39, 135MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.60G/9.95G [00:36<00:33, 158MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.63G/9.95G [00:36<00:28, 183MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.68G/9.95G [00:36<00:24, 213MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.71G/9.95G [00:36<00:24, 217MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.74G/9.95G [00:37<00:23, 221MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.77G/9.95G [00:37<00:23, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.80G/9.95G [00:37<00:22, 230MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.83G/9.95G [00:37<00:21, 236MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.87G/9.95G [00:37<00:21, 242MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.90G/9.95G [00:37<00:19, 253MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.93G/9.95G [00:37<00:19, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.96G/9.95G [00:37<00:19, 256MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.99G/9.95G [00:38<00:19, 256MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.02G/9.95G [00:38<00:18, 262MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.05G/9.95G [00:38<00:19, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.09G/9.95G [00:38<00:18, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.12G/9.95G [00:38<00:19, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.15G/9.95G [00:38<00:18, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.18G/9.95G [00:38<00:18, 256MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.21G/9.95G [00:38<00:17, 267MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.24G/9.95G [00:39<00:17, 265MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.27G/9.95G [00:39<00:16, 275MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.31G/9.95G [00:39<00:18, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.34G/9.95G [00:39<00:19, 240MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.37G/9.95G [00:39<00:18, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.40G/9.95G [00:39<00:17, 265MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.43G/9.95G [00:39<00:16, 270MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.47G/9.95G [00:39<00:15, 284MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.52G/9.95G [00:40<00:14, 300MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.55G/9.95G [00:40<00:15, 278MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.58G/9.95G [00:40<00:22, 199MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.61G/9.95G [00:40<00:21, 201MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.64G/9.95G [00:40<00:21, 198MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.67G/9.95G [00:40<00:19, 216MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.70G/9.95G [00:41<00:20, 204MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.74G/9.95G [00:41<00:19, 214MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.77G/9.95G [00:41<00:21, 196MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.79G/9.95G [00:41<00:21, 197MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.81G/9.95G [00:41<00:21, 189MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.83G/9.95G [00:41<00:22, 181MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.86G/9.95G [00:41<00:20, 202MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.88G/9.95G [00:41<00:20, 201MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.91G/9.95G [00:42<00:19, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.95G/9.95G [00:42<00:18, 218MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.98G/9.95G [00:42<00:21, 189MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.00G/9.95G [00:42<00:21, 188MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.02G/9.95G [00:42<00:21, 180MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.05G/9.95G [00:42<00:20, 191MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.07G/9.95G [00:45<02:14, 28.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.10G/9.95G [00:45<01:33, 41.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.12G/9.95G [00:45<01:15, 50.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.14G/9.95G [00:45<01:01, 61.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.17G/9.95G [00:45<00:50, 75.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.20G/9.95G [00:46<00:38, 96.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.22G/9.95G [00:46<00:35, 104MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.24G/9.95G [00:46<00:31, 119MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.26G/9.95G [00:46<00:36, 101MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.28G/9.95G [00:46<00:37, 99.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.30G/9.95G [00:47<00:44, 82.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.32G/9.95G [00:47<00:43, 84.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.34G/9.95G [00:47<00:35, 102MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.38G/9.95G [00:47<00:27, 129MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.42G/9.95G [00:47<00:22, 157MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.44G/9.95G [00:50<01:55, 30.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.48G/9.95G [00:50<01:13, 47.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.50G/9.95G [00:50<01:02, 54.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.52G/9.95G [00:50<00:52, 65.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.54G/9.95G [00:50<00:42, 79.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.57G/9.95G [00:51<00:31, 106MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.60G/9.95G [00:51<00:28, 119MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.62G/9.95G [00:51<00:26, 126MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.64G/9.95G [00:51<00:26, 124MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.66G/9.95G [00:55<02:57, 18.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.68G/9.95G [00:55<02:21, 23.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.70G/9.95G [00:55<01:44, 31.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.72G/9.95G [00:55<01:21, 39.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.74G/9.95G [00:55<01:02, 51.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.77G/9.95G [00:56<00:42, 74.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.81G/9.95G [00:56<00:31, 101MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.83G/9.95G [00:56<00:28, 108MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.86G/9.95G [00:56<00:23, 134MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.89G/9.95G [00:56<00:18, 164MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.92G/9.95G [00:56<00:16, 183MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.95G/9.95G [00:56<00:14, 209MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.98G/9.95G [00:56<00:13, 227MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 7.01G/9.95G [00:57<00:17, 170MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.06G/9.95G [00:57<00:14, 202MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.09G/9.95G [00:57<00:13, 208MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.13G/9.95G [00:57<00:11, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.16G/9.95G [01:01<01:35, 29.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.19G/9.95G [01:01<01:11, 38.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.22G/9.95G [01:01<00:53, 51.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.27G/9.95G [01:01<00:36, 72.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.30G/9.95G [01:01<00:29, 89.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.33G/9.95G [01:01<00:23, 111MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.36G/9.95G [01:01<00:19, 134MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.39G/9.95G [01:02<00:16, 154MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.42G/9.95G [01:02<00:14, 179MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.46G/9.95G [01:02<00:12, 198MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.49G/9.95G [01:02<00:11, 215MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.52G/9.95G [01:02<00:10, 235MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.55G/9.95G [01:02<00:09, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.59G/9.95G [01:02<00:08, 276MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.62G/9.95G [01:02<00:10, 221MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.65G/9.95G [01:03<00:10, 229MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.69G/9.95G [01:03<00:09, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.72G/9.95G [01:03<00:09, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.75G/9.95G [01:03<00:09, 243MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.78G/9.95G [01:03<00:08, 243MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.81G/9.95G [01:03<00:12, 178MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.83G/9.95G [01:04<00:29, 71.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.85G/9.95G [01:05<00:39, 53.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.89G/9.95G [01:05<00:28, 71.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.91G/9.95G [01:05<00:25, 78.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.94G/9.95G [01:05<00:19, 102MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.97G/9.95G [01:06<00:16, 123MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.99G/9.95G [01:06<00:14, 132MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.01G/9.95G [01:06<00:14, 130MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.03G/9.95G [01:06<00:14, 134MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.06G/9.95G [01:06<00:11, 162MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.10G/9.95G [01:06<00:10, 180MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.12G/9.95G [01:06<00:10, 177MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.14G/9.95G [01:07<00:10, 168MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.16G/9.95G [01:07<00:11, 157MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.18G/9.95G [01:08<00:39, 44.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.20G/9.95G [01:10<01:13, 23.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.22G/9.95G [01:10<00:56, 30.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.23G/9.95G [01:10<00:50, 33.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.24G/9.95G [01:10<00:43, 38.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.25G/9.95G [01:11<00:38, 44.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.29G/9.95G [01:11<00:19, 85.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.33G/9.95G [01:11<00:14, 114MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.36G/9.95G [01:11<00:11, 139MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.39G/9.95G [01:11<00:09, 160MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.42G/9.95G [01:11<00:08, 171MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.44G/9.95G [01:11<00:09, 152MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.46G/9.95G [01:12<00:10, 137MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.49G/9.95G [01:12<00:08, 168MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.54G/9.95G [01:12<00:06, 208MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.57G/9.95G [01:12<00:06, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.60G/9.95G [01:12<00:06, 215MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.63G/9.95G [01:12<00:05, 229MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.66G/9.95G [01:12<00:05, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.69G/9.95G [01:12<00:04, 262MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.72G/9.95G [01:13<00:04, 262MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.76G/9.95G [01:13<00:04, 266MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.79G/9.95G [01:13<00:04, 254MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.82G/9.95G [01:13<00:04, 255MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.85G/9.95G [01:13<00:04, 255MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.88G/9.95G [01:13<00:04, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.91G/9.95G [01:13<00:04, 258MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.94G/9.95G [01:13<00:03, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.98G/9.95G [01:14<00:03, 260MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.01G/9.95G [01:14<00:03, 268MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.04G/9.95G [01:14<00:03, 265MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.07G/9.95G [01:14<00:03, 265MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.10G/9.95G [01:14<00:03, 273MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.14G/9.95G [01:14<00:02, 287MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.19G/9.95G [01:14<00:02, 256MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.22G/9.95G [01:15<00:03, 220MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.25G/9.95G [01:15<00:03, 229MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.28G/9.95G [01:15<00:02, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.31G/9.95G [01:15<00:02, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.34G/9.95G [01:15<00:02, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.38G/9.95G [01:15<00:01, 286MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.42G/9.95G [01:15<00:02, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.45G/9.95G [01:15<00:02, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.48G/9.95G [01:16<00:02, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.51G/9.95G [01:16<00:02, 210MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.54G/9.95G [01:16<00:03, 127MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.56G/9.95G [01:20<00:17, 22.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.59G/9.95G [01:20<00:12, 29.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.63G/9.95G [01:20<00:07, 41.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.66G/9.95G [01:20<00:05, 56.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.69G/9.95G [01:21<00:03, 72.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.72G/9.95G [01:21<00:02, 89.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.74G/9.95G [01:21<00:02, 102MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.77G/9.95G [01:21<00:01, 127MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.80G/9.95G [01:21<00:01, 141MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.84G/9.95G [01:21<00:00, 161MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.87G/9.95G [01:21<00:00, 181MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.90G/9.95G [01:22<00:00, 193MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.95G/9.95G [01:22<00:00, 121MB/s]\n","Downloading shards:  50% 1/2 [01:22<01:22, 82.77s/it]\n","pytorch_model-00002-of-00002.bin:   0% 0.00/4.48G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 31.5M/4.48G [00:00<00:14, 302MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 62.9M/4.48G [00:00<00:16, 272MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   2% 94.4M/4.48G [00:00<00:15, 278MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   3% 126M/4.48G [00:00<00:20, 209MB/s] \u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 157M/4.48G [00:00<00:22, 194MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 178M/4.48G [00:00<00:22, 188MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 199M/4.48G [00:00<00:23, 184MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   5% 220M/4.48G [00:02<02:00, 35.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   6% 252M/4.48G [00:02<01:22, 51.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   6% 273M/4.48G [00:03<01:09, 60.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 294M/4.48G [00:03<00:56, 73.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 325M/4.48G [00:03<00:41, 99.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 357M/4.48G [00:03<00:33, 123MB/s] \u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 377M/4.48G [00:03<00:30, 136MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 398M/4.48G [00:03<00:28, 144MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 419M/4.48G [00:03<00:30, 131MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 440M/4.48G [00:07<03:10, 21.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 461M/4.48G [00:07<02:58, 22.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 482M/4.48G [00:07<02:13, 30.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 503M/4.48G [00:08<01:42, 38.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  12% 524M/4.48G [00:08<01:18, 50.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  12% 545M/4.48G [00:08<01:11, 55.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 566M/4.48G [00:08<00:56, 69.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 587M/4.48G [00:08<00:45, 85.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 608M/4.48G [00:08<00:38, 101MB/s] \u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 629M/4.48G [00:09<00:32, 119MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 661M/4.48G [00:09<00:24, 154MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 692M/4.48G [00:09<00:22, 170MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 724M/4.48G [00:09<00:19, 194MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  17% 755M/4.48G [00:09<00:17, 209MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  18% 786M/4.48G [00:09<00:17, 207MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  18% 818M/4.48G [00:09<00:18, 201MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 849M/4.48G [00:10<00:22, 162MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 870M/4.48G [00:10<00:35, 101MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  20% 902M/4.48G [00:10<00:28, 127MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  21% 944M/4.48G [00:10<00:21, 161MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 975M/4.48G [00:10<00:18, 185MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 1.01G/4.48G [00:11<00:16, 208MB/s]\u001b[A"]}],"source":["!autotrain llm \\\n","--train \\\n","--model ${MODEL_NAME} \\\n","--project-name ${PROJECT_NAME} \\\n","--data-path data/ \\\n","--text-column text \\\n","--lr ${LEARNING_RATE} \\\n","--batch-size ${BATCH_SIZE} \\\n","--epochs ${NUM_EPOCHS} \\\n","--block-size ${BLOCK_SIZE} \\\n","--warmup-ratio ${WARMUP_RATIO} \\\n","--lora-r ${LORA_R} \\\n","--lora-alpha ${LORA_ALPHA} \\\n","--lora-dropout ${LORA_DROPOUT} \\\n","--weight-decay ${WEIGHT_DECAY} \\\n","--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n","$( [[ \"$USE_FP16\" == \"True\" ]]) \\\n","$( [[ \"$USE_PEFT\" == \"True\" ]]) \\\n","$( [[ \"$USE_INT4\" == \"True\" ]] ) \\\n","$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0aaad9c9c9a54bd1ac96bd56642ab50e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aa1e0640bb54cd3812a5b0f9e019f77","placeholder":"â€‹","style":"IPY_MODEL_f1a3135e5daf48f49f872b7d9737a18a","value":"Creating CSV from Arrow format: 100%"}},"1828ff91e5484015aaff4f2fe3567f0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"274be5774d064ae58234b2dd97395ce3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b727086f1ed546a5bb5f756b546d25f8","placeholder":"â€‹","style":"IPY_MODEL_70fff442a717469687add4cdd988d418","value":" 6/6 [00:00&lt;00:00, 49.72ba/s]"}},"2aa1e0640bb54cd3812a5b0f9e019f77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b3d44894e14e5ab486d1b9d6aefe01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aaad9c9c9a54bd1ac96bd56642ab50e","IPY_MODEL_78ac3a5f84e349ec98a82fc24c5fd7a3","IPY_MODEL_274be5774d064ae58234b2dd97395ce3"],"layout":"IPY_MODEL_fd14948de6a840fa86dff66153a4afbc"}},"70fff442a717469687add4cdd988d418":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78ac3a5f84e349ec98a82fc24c5fd7a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91e6ea75794b4e458806ddca4ebf569b","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1828ff91e5484015aaff4f2fe3567f0a","value":6}},"91e6ea75794b4e458806ddca4ebf569b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b727086f1ed546a5bb5f756b546d25f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a3135e5daf48f49f872b7d9737a18a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd14948de6a840fa86dff66153a4afbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
